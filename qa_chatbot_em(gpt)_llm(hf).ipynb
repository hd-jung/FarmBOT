{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q langchain openai tiktoken chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget -q https://github.com/kairess/toy-datasets/raw/master/techcrunch-articles.zip\n",
    "# !unzip -q techcrunch-articles.zip -d articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2002"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loader = TextLoader('single_text_file.txt')\n",
    "# loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "# loader = DirectoryLoader('./articles', glob=\"*.txt\", loader_cls=TextLoader)\n",
    "loader = DirectoryLoader('./articles', glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2424"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "# 1000글자씩 분할하기\n",
    "# 끊기는것을 방지하지 위해 겹치는 부분을 200자로 제한함.\n",
    "texts = text_splitter.split_documents(documents)\n",
    "\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='70.7%\\n12.6%\\n6.3%10.4%37.8%\\n18.2%\\n9.4%34.6%\\n귀농 귀촌\\n1\\n2\\n3\\n4\\n5\\n6', metadata={'source': 'articles\\\\(농업정책관-청년농육성정책팀) 2022년 귀농귀촌실태조사 결과 보도자료(3.3. 조간)_별첨(2022년 귀농귀촌실태조사 결과  인포그래픽).pdf', 'page': 0}),\n",
       " Document(page_content='∙\\n일반직장\\n취업자영업 임시직 농사일 비농업부문\\n일용직농업임금노동\\n6.4% 83.3%귀농 귀촌 (만원)\\n2,3183,099 3,055 3,1483,186 3,2063,4543,6853,877 3,929 3,8084,045\\n귀농, 귀촌첫해\\n(전체평균)1년차 2년차 3년차\\n 5년차\\n57.4%\\n22.7%\\n7.4% 5.0% 3.1% 2.6%\\n귀농\\n 귀촌\\n∙', metadata={'source': 'articles\\\\(농업정책관-청년농육성정책팀) 2022년 귀농귀촌실태조사 결과 보도자료(3.3. 조간)_별첨(2022년 귀농귀촌실태조사 결과  인포그래픽).pdf', 'page': 1})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create Chroma DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db' # 'db' 디렉토리에 저장함.\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "# openai의 embedding을 사용함\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=texts, \n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화 하는 하는 과정\n",
    "vectordb.persist()\n",
    "vectordb = None\n",
    "persist_directory = 'chroma_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma(\n",
    "    persist_directory=persist_directory, \n",
    "    embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever()\n",
    "# docs = retriever.get_relevant_documents(\"What is Generative AI?\")\n",
    "\n",
    "# for doc in docs:\n",
    "#     print(doc.metadata[\"source\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make a chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "e:\\Installation\\Anaconda3\\envs\\py311_gpu\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1ceaea2f68425f9f6bab0fe8a07bcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import os\n",
    "# model_id = 'maywell/Synatra-42dot-1.3B'\n",
    "model_id = 'zomd/AISquare-Instruct-yi-ko-6b-v0.9.30'\n",
    "os.environ['HF_HOME'] = r'./models'\n",
    "\n",
    "llm = HuggingFacePipeline.from_model_id(\n",
    "    model_id=model_id, \n",
    "    device=0,               # -1: CPU(default), 0번 부터는 CUDA 디바이스 번호 지정시 GPU 사용하여 추론\n",
    "    task=\"text-generation\", # 텍스트 생성\n",
    "    model_kwargs={\"temperature\": 0.2, \n",
    "                  \"max_length\": 2000},\n",
    ")\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=retriever, \n",
    "    return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_llm_response(llm_response):\n",
    "    print(llm_response['result'])\n",
    "    print('\\n\\nSources:')\n",
    "    for source in llm_response[\"source_documents\"]:\n",
    "        print(source.metadata['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Installation\\Anaconda3\\envs\\py311_gpu\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "e:\\Installation\\Anaconda3\\envs\\py311_gpu\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
      "  warnings.warn(\n",
      "e:\\Installation\\Anaconda3\\envs\\py311_gpu\\Lib\\site-packages\\transformers\\generation\\utils.py:1518: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "e:\\Installation\\Anaconda3\\envs\\py311_gpu\\Lib\\site-packages\\transformers\\generation\\configuration_utils.py:389: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 사과 재배 방법\n",
      "\n",
      "사과 재배 방법은 다음과 같습니다:\n",
      "\n",
      "1. 토양 관리: 사과 나무가 자라는 토양은 배수가 잘되고 비옥해야 합니다. 토양을 개선하기 위해 유기물과 석회질을 사용하여 토양을 개량할 수 있습니다.\n",
      "\n",
      "2. 씨앗 준비: 사과 씨앗은 12-14주 동안 저온에 보관해야 합니다. 사과 나무는 3월 중순에 심어야 합니다.\n",
      "\n",
      "3. 가지치기: 사과 나무는 2-3년 동안 가지치기를 해야 합니다. 가지치기는 나무의 성장을 조절하고 과실의 품질을 개선할 수 있습니다.\n",
      "\n",
      "4. 병충해 관리: 사과 나무는 사과나무에 해를 끼치는 병충해를 예방하기 위해 정기적으로 살충제와 살균제를 사용해야 합니다.\n",
      "\n",
      "5. 수분 관리: 사과 나무는 충분한 수분을 유지하기 위해 정기적으로 관수를 해야 합니다.\n",
      "\n",
      "2. 사과 품질 관리\n",
      "\n",
      "사과 품질을 관리하기 위한 몇 가지 방법이 있습니다:\n",
      "\n",
      "1. 수확: 사과는 완전히 익었을 때 수확해야 합니다. 너무 일찍 수확하면 과실이 덜 익거나 맛이 없을 수 있습니다.\n",
      "\n",
      "2. 저장: 수확한 사과를 저장하려면 1-2°C의 온도와 80-90%의 습도를 유지해야 합니다.\n",
      "\n",
      "3. 선별: 사과는 크기, 모양, 색, 흠집, 병충해 등을 기준으로 선별해야 합니다.\n",
      "\n",
      "4. 포장: 사과는 흠집이 생기지 않도록 잘 포장해야 합니다.\n",
      "\n",
      "5. 마케팅: 사과는 신선하고 품질 좋은 것으로 홍보해야 합니다.\n",
      "\n",
      "결론적으로, 사과 재배와 품질 관리를 위한 방법은 토양 관리, 씨앗 준비, 가지치기, 병충해 관리, 수분 관리, 수확, 저장, 선별, 포장 및 마케팅을 포함합니다.\n",
      "\n",
      "\n",
      "Sources:\n"
     ]
    }
   ],
   "source": [
    "# query = \"벼 농사가 망했을때 보상받을 수 있는 방법에 대해 알려줘\"\n",
    "# query = \"사업자 등록을 위해 구비해야할 서류는 뭐가 있을까?\"\n",
    "query = \"사과 재배하는 방법과, 사과 품질을 관리하는 방법을 알려줘\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '사과 재배하는 방법과, 사과 품질을 관리하는 방법을 알려줘',\n",
       " 'result': '\\n\\n1. 사과 재배 방법\\n\\n사과 재배 방법은 다음과 같습니다:\\n\\n1. 토양 관리: 사과 나무가 자라는 토양은 배수가 잘되고 비옥해야 합니다. 토양을 개선하기 위해 유기물과 석회질을 사용하여 토양을 개량할 수 있습니다.\\n\\n2. 씨앗 준비: 사과 씨앗은 12-14주 동안 저온에 보관해야 합니다. 사과 나무는 3월 중순에 심어야 합니다.\\n\\n3. 가지치기: 사과 나무는 2-3년 동안 가지치기를 해야 합니다. 가지치기는 나무의 성장을 조절하고 과실의 품질을 개선할 수 있습니다.\\n\\n4. 병충해 관리: 사과 나무는 사과나무에 해를 끼치는 병충해를 예방하기 위해 정기적으로 살충제와 살균제를 사용해야 합니다.\\n\\n5. 수분 관리: 사과 나무는 충분한 수분을 유지하기 위해 정기적으로 관수를 해야 합니다.\\n\\n2. 사과 품질 관리\\n\\n사과 품질을 관리하기 위한 몇 가지 방법이 있습니다:\\n\\n1. 수확: 사과는 완전히 익었을 때 수확해야 합니다. 너무 일찍 수확하면 과실이 덜 익거나 맛이 없을 수 있습니다.\\n\\n2. 저장: 수확한 사과를 저장하려면 1-2°C의 온도와 80-90%의 습도를 유지해야 합니다.\\n\\n3. 선별: 사과는 크기, 모양, 색, 흠집, 병충해 등을 기준으로 선별해야 합니다.\\n\\n4. 포장: 사과는 흠집이 생기지 않도록 잘 포장해야 합니다.\\n\\n5. 마케팅: 사과는 신선하고 품질 좋은 것으로 홍보해야 합니다.\\n\\n결론적으로, 사과 재배와 품질 관리를 위한 방법은 토양 관리, 씨앗 준비, 가지치기, 병충해 관리, 수분 관리, 수확, 저장, 선별, 포장 및 마케팅을 포함합니다.',\n",
       " 'source_documents': []}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"Who led the round in Pando?\"\n",
    "# llm_response = qa_chain(query)\n",
    "# process_llm_response(llm_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
